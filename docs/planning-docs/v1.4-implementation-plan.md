# v1.4 Implementation Plan - Close the Loop (Performance â†’ Action)

## Executive Summary

**Goal**: Transform static keyword plans into an adaptive system that learns from real Google Ads performance data, automatically proposing optimizations to reduce waste and improve Quality Score.

**Timeline**: 3-5 days
**Priority**: HIGH - Direct ROI through waste reduction and QS improvement
**Complexity**: Medium-High (new ingestion pipelines, n-gram analysis)

## Core Deliverables

### 1. Waste Analysis & Negative Keywords
- **waste_report.md**: Detailed analysis of high-spend/no-conversion search terms
- **negatives_proposed.csv**: Google Ads Editor import-ready negative keywords
- **negatives_proposed.json**: API-ready format for automated application

### 2. Quality Score Optimization
- **qs_triage.md**: Ad groups ranked by QS issues with specific fixes
- **Automated recommendations** for Expected CTR, Ad Relevance, Landing Page Experience

### 3. Paid/Organic Synergy
- **paid_organic_gaps.md**: Opportunities where SEO wins but ads don't cover (and vice versa)
- **Cross-channel recommendations** for keyword and page alignment

## Technical Architecture

### Phase 1: Data Ingestion Layer (Day 1)

#### Task 1.1: Google Ads Search Terms Connector
```typescript
// src/connectors/google-ads-performance.ts
export class GoogleAdsPerformanceConnector {
  // GAQL approach (primary)
  async fetchSearchTerms(customerId: string, dateRange: DateRange): Promise<SearchTermData[]>
  
  // CSV fallback approach
  async importSearchTermsCSV(filePath: string): Promise<SearchTermData[]>
  
  // Quality Score fetching
  async fetchQualityScores(customerId: string): Promise<QualityScoreData[]>
}
```

**Implementation Notes**:
- Use GAQL for real-time data: `SELECT search_term, clicks, impressions, cost, conversions FROM search_term_view`
- CSV import path: `inputs/google_ads/search_terms_<product>_<period>.csv`
- Cache with 24h TTL to reduce API calls

#### Task 1.2: Analytics Integration
```typescript
// src/connectors/analytics-connector.ts
export class AnalyticsConnector {
  // GA4 events (CWS_Click, Waitlist_Submit)
  async fetchConversionEvents(dateRange: DateRange): Promise<ConversionEvent[]>
  
  // Plausible pageviews by UTM (optional)
  async fetchPageviews(utmParams: UTMParams): Promise<PageviewData[]>
}
```

### Phase 2: N-gram Analysis Engine (Day 2)

#### Task 2.1: N-gram Processor
```typescript
// src/analyzers/ngram-engine.ts
export class NgramEngine {
  private stopWords = ['the', 'a', 'an', 'and', 'or', 'but', ...];
  private minLength = 2;
  
  // Core n-gram extraction
  extractNgrams(searchTerms: string[], n: number): Map<string, NgramStats>
  
  // Waste identification
  identifyWastedSpend(ngrams: Map<string, NgramStats>): WastedTerm[]
  
  // Negative keyword generation
  generateNegatives(wastedTerms: WastedTerm[]): NegativeKeyword[]
}
```

**Key Logic**:
- Lowercase normalization
- Remove stop words
- Aggregate 30-day spend & conversions
- Flag zero-conversion terms with spend > $10
- Flag low-CTR terms (<0.5%) with >100 impressions

#### Task 2.2: Negative Placement Rules
```typescript
// src/analyzers/negative-placement.ts
export class NegativePlacementEngine {
  // Placement hierarchy
  determineLevel(negative: NegativeKeyword): 'shared' | 'campaign' | 'adGroup'
  
  // Shared list: non-intent words (jobs, tutorial, free)
  // Campaign level: platform mismatches (firefox, safari)
  // Ad group level: tight use-case cleanup
}
```

### Phase 3: Quality Score Triage System (Day 3)

#### Task 3.1: QS Analyzer
```typescript
// src/analyzers/quality-score-analyzer.ts
export class QualityScoreAnalyzer {
  // Join QS data with landing page health
  async analyzeQualityScore(qsData: QualityScoreData[], urlHealth: URLHealthData[]): Promise<QSAnalysis[]>
  
  // Bucket issues by component
  categorizeIssues(analysis: QSAnalysis): {
    adRelevance: AdRelevanceIssue[]
    lpExperience: LPExperienceIssue[]
    expectedCTR: ExpectedCTRIssue[]
  }
  
  // Generate specific fixes
  generateRecommendations(issues: CategorizedIssues): QSRecommendation[]
}
```

**Recommendation Logic**:
- **Ad Relevance < 5**: Add primary keyword to headline/description
- **LP Experience < 5**: Fix noindex/404/slow pages, add internal links
- **Expected CTR < 5**: Add proof/urgency headline, test extensions

#### Task 3.2: Paid/Organic Gap Analysis
```typescript
// src/analyzers/paid-organic-analyzer.ts
export class PaidOrganicAnalyzer {
  // Identify gaps
  findGaps(paidData: PaidData[], organicData: OrganicData[]): {
    seoWinsNoPaid: Opportunity[]
    paidWinsNoSEO: Opportunity[]
    bothWinning: Synergy[]
  }
  
  // Generate recommendations
  recommendActions(gaps: Gaps): PaidOrganicRecommendation[]
}
```

### Phase 4: Database Schema & Storage (Day 3-4)

#### Task 4.1: New Tables
```sql
-- Search terms performance
CREATE TABLE fact_search_terms (
  date DATE,
  engine TEXT DEFAULT 'google',
  campaign_id TEXT,
  ad_group_id TEXT,
  query TEXT,
  match_type TEXT,
  clicks INTEGER,
  impressions INTEGER,
  cost REAL,
  conversions REAL,
  conv_value REAL,
  PRIMARY KEY (date, campaign_id, ad_group_id, query)
);

-- Quality Score tracking
CREATE TABLE fact_qs (
  date DATE,
  campaign_id TEXT,
  ad_group_id TEXT,
  expected_ctr INTEGER,
  ad_relevance INTEGER,
  lp_experience INTEGER,
  quality_score INTEGER,
  PRIMARY KEY (date, campaign_id, ad_group_id)
);

-- Event tracking (optional)
CREATE TABLE fact_events (
  date DATE,
  source TEXT,
  event_name TEXT,
  sessions INTEGER,
  count INTEGER,
  PRIMARY KEY (date, source, event_name)
);

-- Negative keyword tracking
CREATE TABLE proposed_negatives (
  id TEXT PRIMARY KEY,
  proposed_date DATE,
  keyword TEXT,
  match_type TEXT,
  placement_level TEXT,
  reason TEXT,
  waste_amount REAL,
  status TEXT DEFAULT 'proposed',
  applied_date DATE
);
```

### Phase 5: CLI Commands & Orchestration (Day 4)

#### Task 5.1: New CLI Commands
```typescript
// src/cli-v14.ts
program
  .command('ingest-ads')
  .description('Import Google Ads performance data')
  .option('--product <product>', 'Product name')
  .option('--from <source>', 'Data source: gaql|csv')
  .option('--file <path>', 'CSV file path if source=csv')
  .action(ingestAdsCommand);

program
  .command('propose-negatives')
  .description('Analyze waste and propose negative keywords')
  .option('--product <product>', 'Product name')
  .option('--window <days>', 'Analysis window (default: 30d)')
  .option('--min-spend <amount>', 'Minimum wasted spend threshold')
  .option('--min-impr <count>', 'Minimum impressions threshold')
  .action(proposeNegativesCommand);

program
  .command('qs-triage')
  .description('Analyze and triage Quality Score issues')
  .option('--product <product>', 'Product name')
  .action(qsTriageCommand);

program
  .command('paid-organic')
  .description('Analyze paid/organic gaps')
  .option('--product <product>', 'Product name')
  .action(paidOrganicCommand);
```

### Phase 6: Output Writers (Day 4-5)

#### Task 6.1: Waste Report Writer
```typescript
// src/writers/waste-report-writer.ts
export class WasteReportWriter {
  generateReport(wastedTerms: WastedTerm[]): string {
    // Markdown report with:
    // - Executive summary (total waste, top offenders)
    // - Detailed n-gram analysis
    // - Proposed negative keywords by level
    // - Expected savings calculation
  }
}
```

#### Task 6.2: Negatives CSV Writer
```typescript
// src/writers/negatives-csv-writer.ts
export class NegativesCsvWriter {
  // Google Ads Editor format
  generateEditorCSV(negatives: NegativeKeyword[]): string
  
  // API format
  generateAPIJson(negatives: NegativeKeyword[]): object
}
```

## Testing Strategy

### Unit Tests
- N-gram extraction with various inputs
- Negative keyword placement logic
- QS issue categorization
- Gap analysis algorithms

### Integration Tests
- GAQL query execution
- CSV import validation
- Database persistence
- End-to-end workflow

### Acceptance Tests
1. **Negatives Import**: CSV imports cleanly in Google Ads Editor
2. **Waste Identification**: Report shows concrete n-grams with spend data
3. **QS Fixes**: At least 3 specific recommendations per low-QS ad group
4. **Idempotency**: No duplicate negatives re-proposed

## Risk Mitigation

### Technical Risks
1. **Low Volume Data**: Widen analysis window to 60-90 days
2. **Conversion Lag**: Implement "do-not-suggest-again" list with 30-day expiry
3. **API Quotas**: Aggressive caching, batch operations

### Business Risks
1. **Over-blocking**: Conservative thresholds, manual review required
2. **False Negatives**: Track applied negatives performance for 14 days

## Success Metrics

### Immediate (Day 1 after launch)
- Waste report identifies >$100 in wasted spend
- At least 20 negative keywords proposed
- QS triage covers 80% of ad groups

### Week 1
- 10% reduction in wasted spend
- Average QS improvement of 0.5 points
- 5 high-value paid/organic gaps identified

### Month 1
- 25% waste reduction
- 1-point QS improvement average
- CTR improvement of 15%

## Implementation Schedule

### Day 1: Data Ingestion
- [ ] Morning: Google Ads Performance connector (GAQL)
- [ ] Afternoon: CSV import fallback
- [ ] Evening: Analytics connector (GA4/Plausible)

### Day 2: Analysis Engine
- [ ] Morning: N-gram processor
- [ ] Afternoon: Negative placement rules
- [ ] Evening: Unit tests for analyzers

### Day 3: Quality & Gaps
- [ ] Morning: Quality Score analyzer
- [ ] Afternoon: Paid/Organic gap analyzer
- [ ] Evening: Database schema implementation

### Day 4: CLI & Integration
- [ ] Morning: CLI commands
- [ ] Afternoon: Orchestration logic
- [ ] Evening: Integration tests

### Day 5: Writers & Polish
- [ ] Morning: Report writers
- [ ] Afternoon: CSV/JSON exporters
- [ ] Evening: End-to-end testing, documentation

## Dependencies

### External APIs
- Google Ads API (search_term_view, ad_group_criterion)
- Google Analytics 4 API (optional)
- Plausible API (optional)

### Internal Systems
- Existing orchestrator framework
- Cache manager
- Database connection pool

## Documentation Requirements

1. **User Guide**: How to interpret waste reports and apply negatives
2. **API Reference**: New CLI commands and options
3. **Technical Docs**: N-gram algorithm, placement rules

## Rollout Plan

### Phase 1: Internal Testing
- Run on ConvertMyFile data
- Manual review of all proposals
- Track actual savings

### Phase 2: Soft Launch
- Enable for all products
- Daily monitoring of proposals
- A/B test negative application

### Phase 3: Full Automation
- Auto-apply low-risk negatives
- Slack alerts for high waste
- Weekly performance reports

## Future Enhancements

1. **Machine Learning**: Predict waste before it happens
2. **Competitor Analysis**: Identify competitor bidding patterns
3. **Budget Optimization**: Redistribute budget from waste to winners
4. **Custom Alerts**: Configurable thresholds and channels

---

**Estimated Effort**: 3-5 days
**Complexity**: Medium-High
**ROI**: High (immediate cost savings)
**Risk**: Low (read-only analysis, manual application)