# v1.4 — Close the loop (performance ingestion → action)

Goal: Turn plans into an adaptive system that learns from real data.
Time: 3–5 days

## Deliverables (new files per run)
	•	waste_report.md — high-spend/no-conversion n-grams with proposed negatives (shared/campaign/ad group level).
	•	negatives_proposed.csv — import-ready (Editor CSV) and negatives_proposed.json for API path.
	•	qs_triage.md — ad groups ranked by Quality Score drivers (Expected CTR, Ad Relevance, LP Experience) with concrete fixes.
	•	paid_organic_gaps.md — where SEO wins but ads don’t cover (and vice versa), with page/keyword recommendations.

## Connectors / ingestion
	•	Google Ads search terms (choose one now, keep both code paths):
	•	GAQL → search_term_view + metrics; or
	•	CSV import: inputs/google_ads/search_terms_<product>_<period>.csv.
	•	Quality Score (GAQL): per ad group (expected CTR/ad relevance/LP experience/QS).
	•	Paid & Organic: if linked, CSV import for now.
	•	Analytics: read-only GA4 events (CWS_Click, Waitlist_Submit) + Plausible pageviews by UTM (optional but recommended).

## Logic
	•	N-gram engine: lowercase, tokenizer, stop-words, min-length; aggregate 30-day spend & conversions; flag zero-conv & low-CTR terms.
	•	Negative placement rules:
	•	Shared list for non-intent words across groups (e.g., “jobs”, “tutorial”, platform mismatches).
	•	Campaign level for channel/platform mismatches (e.g., “firefox” in Chrome campaigns).
	•	Ad group level for tight clean-up (e.g., irrelevant modifiers within a use-case cluster).
	•	QS triage: join fact_qs with url_health.json; bucket causes:
	•	Ad Relevance: headline/keyword misalignment → suggest adding primary keyword to one headline/desc.
	•	LP Experience: noindex/soft-404/thin/slow → page fixes + internal links.
	•	Expected CTR: add a proof or urgency headline; test sitelinks/callouts.

## DB changes (SQLite/DuckDB)
	•	fact_search_terms(date, engine, campaign_id, ad_group_id, query, match_type, clicks, impressions, cost, conversions, conv_value)
	•	fact_qs(date, campaign_id, ad_group_id, expected_ctr, ad_relevance, lp_experience, quality_score)
	•	(optional) fact_events(date, source, event_name, sessions, count) for GA4/Plausible.

## CLI

seo-ads plan --product convertmyfile --markets AU,US,GB
seo-ads ingest-ads --product convertmyfile --from gaql|csv path/to/file.csv
seo-ads propose-negatives --product convertmyfile --window 30d --min-spend 10 --min-impr 100
seo-ads apply-negatives --product convertmyfile --confirm   # guarded Ads API path
seo-ads qs-triage --product convertmyfile
seo-ads paid-organic --product convertmyfile

## Acceptance gates
	•	negatives_proposed.csv imports cleanly in Ads Editor; API path refuses without --confirm.
	•	waste_report.md shows concrete n-grams with spend & zero conversions; not hand-wavy.
	•	qs_triage.md lists at least three specific ad/LP fixes for low-QS groups.
	•	No duplicate negatives re-proposed (hash/idempotency).

## Risks / blind spots
	•	Low volume early on → widen 60–90d windows.
	•	False negatives if conversion lag > window → keep a “do-not-suggest-again” list with expiry.

⸻

# v1.5 — Experiments (RSA + Landing Pages) with auto-analysis

Goal: Systematically improve CTR & CVR with minimal spend.
Time: 4–6 days

## Deliverables
	•	experiments.json — registry of active/paused tests (type, variants, start/end, guards).
	•	experiments.md — human summary (what’s being tested, why, success metric, stop rule).
	•	experiment_results_<id>.json — stats for each test (uplift, CI, decision).
	•	Exports:
	•	RSAs: Editor CSV with variant ads (paused by default) + labels (EXP_BENEFIT, EXP_PROOF).
	•	LP A/B: content files for A and B variants (or content blocks), with routing toggle.

## What to test
	•	RSA variants per ad group:
	•	Benefit-led vs Proof-led; always keep the pinned “Chrome Extension” headline.
	•	Similarity guard: compute cosine similarity on headline embeddings; if >0.9, regenerate copy.
	•	LP variants per primary use-case page:
	•	Variant B changes: headline framing, above-the-fold proof block, FAQs order, social proof snippet.

## Measurement
	•	Ads: clicks, cost, impressions per ad (GAQL).
	•	Site: GA4/Plausible events (LP_View, CWS_Click) with UTM; map back to ad/variant via ValueTrack ({creative} label).
	•	Decision engine: two-proportion test or Bayesian A/B (Beta) for CTR and CWS_Click rate. Minimum sample guard (e.g., ≥200 clicks per arm or 95% CI width < target).

## DB changes
	•	fact_ab_tests(test_id, type, product, ad_group_id/page_id, start_at, end_at, status, target_metric)
	•	fact_ab_variants(test_id, variant_id, label, copy_hash, lp_path)
	•	fact_ab_metrics(date, test_id, variant_id, impressions, clicks, cws_clicks, cost)

## CLI

seo-ads start-experiment rsa --product convertmyfile --ad-group "WebP PNG" --variants benefit,proof
seo-ads start-experiment lp  --product convertmyfile --page /convertmyfile/webp-to-png --variant "ProofBlock"
seo-ads analyze-experiment --test-id EXP-123 --min-clicks 200
seo-ads stop-experiment --test-id EXP-123 --accept winner|fallback A

## Acceptance gates
	•	RSA variant CSV imports cleanly; variants are initially paused (no accidental spend).
	•	LP A/B routing respects a cookie param (first view → assign arm; sticky for 7 days).
	•	experiment_results_*.json shows statistically justified decisions (pass/fail/need more data).
	•	Writers never output near-duplicate RSA variants (similarity guard in place).

## Risks
	•	Tiny traffic → tests stall; add global “small-n mode” using pooled priors and longer windows.
	•	Policy: keep claims validator on variants; refuse if claim not validated for that use-case.

⸻

# v1.6 — Microsoft Ads parity + Edge store uplift

Goal: Capture Edge/Bing users and align store listings to search demand.
Time: 4–6 days

## Deliverables
	•	msads_editor/ — Microsoft Advertising bulk import CSVs mirroring Google structure:
	•	campaigns.csv, ad_groups.csv, keywords_exact.csv, keywords_phrase.csv,
ads_rsa.csv (assets & pinning mapped), sitelinks.csv, callouts.csv,
structured_snippets.csv, shared_negative_list.csv, associations.csv.
	•	msads_mapping.md — field-by-field map (Google → Microsoft) + known differences.
	•	edge_store_audit.md — checklist + recommended titles/short/long descriptions/keywords aligned to clusters; flags for missing screenshots/video.
	•	(Optional) bing_webmaster.md — verify + sitemap submit instructions (if you want SEO parity too).

## Implementation notes
	•	Field mapping highlights:
	•	Match types: (Exact, Phrase) similar; Broad off.
	•	RSAs: asset count/pinning rules slightly differ—test an import and mimic the accepted format.
	•	Labels: supported; keep your LBA_SEO_ADS_EXPERT_YYYYMMDD.
	•	Tracking template syntax differs: map {campaignid}/{adgroupid} to Microsoft tokens; emit channel-specific UTM suffix.
	•	Shared negatives: create a shared list per product; associate to all campaigns.
	•	Geo/Lang: mirror AU/US/GB; use English locales.
	•	Bids/Budget: start with conservative daily caps; desktop-first device adj.

## Edge Add-ons Store uplift
	•	Parse your listing (or accept manual paste of current content).
	•	Emit edge_store_audit.md with:
	•	Title ≤ 45 chars including use-case keyword (e.g., “PaletteKit – Color Picker for Edge”).
	•	Short description variants (A/B suggestions).
	•	Long description outline (features → how-to
	
seo-ads export-msads --product convertmyfile --markets AU,US,GB
seo-ads validate-msads --path plans/.../msads_editor/  # schema & basic sanity
seo-ads edge-store-audit --product palettekit

## Acceptance gates
	•	Microsoft bulk imports without schema errors (test in sandbox).
	•	RSA pinning/asset counts accepted by Microsoft (no silent truncation).
	•	Edge store audit lists keyword-aligned title/desc with character-count checks.

## Risks
	•	Microsoft bulk format evolves; lock a golden export and byte-compare your CSV headers in tests.
	•	Store rules differ; treat audit as recommendations, not auto-apply.

⸻

## Cross-version shared improvements (do during 1.4–1.6)
	•	Alerts (lightweight): add a cronable check that writes alerts.json if CTR/QS drops > X% or spend spikes; you’ll wire Slack later.
	•	Plan runtime budgets: log per-connector timings; fail fast if SERP calls hit quota or runtime > 2m (cold) / 60s (warm).
	•	Snapshot tests on bytes: CSV/JSON/MD byte-level snapshots to prevent schema drift.
	•	Immutable plan runs: keep plans/<product>/<date>/ read-only after generation; new runs create new dated dirs + DB facts.
	
## What I’d build first (order of impact)
1.	v1.4 (negatives + QS triage). It saves real money fast.
	2.	v1.5 (RSA/LP experiments). Small, compounding wins on CTR/CWS.
	3.	v1.6 (MsAds + Edge store). Expands reach where your users live.
