# üöÄ Test Remediation Execution Guide - START HERE

**Created**: 2025-09-30
**Purpose**: Execute comprehensive fix plan for 181 failing tests
**Target**: 100% test pass rate (1,002/1,002 tests)
**Estimated Time**: 50-60 hours (7-10 working days)

---

## üìã Quick Start (First 5 Minutes)

### Step 1: Read the Master Plan
**File**: `docs/OPTION_A_COMPREHENSIVE_FIX_PLAN.md` (2,100 lines)

This is your **primary execution document**. It contains:
- Complete 8-phase remediation strategy (Phase 0-7)
- Detailed code examples for every fix
- Test-by-test breakdown (all 181 failures mapped)
- Quality gates and verification steps
- Commit hygiene guidelines

**Action**: Read the executive summary (first 100 lines) to understand the approach.

### Step 2: Start with Phase 0 (Infrastructure)
**Time**: 1.5 hours
**Goal**: Create shared utilities used by all later phases

**Tasks**:
1. Create `src/utils/date-adapter.ts` (45 min)
2. Create `src/utils/time-source.ts` (30 min)
3. Create `tests/fixtures/index.ts` (15 min)

**Why First**: Prevents repeated work across Phases 1-7, saves 3-4 hours total.

### Step 3: Execute Phases 1-7 Systematically
Follow the plan exactly as written. After each phase:
- ‚úÖ Run affected tests
- ‚úÖ Verify pass rate improvement
- ‚úÖ Check quality gates
- ‚úÖ Commit with clear message
- ‚úÖ Update progress in `.claude-context`

---

## ‚ö†Ô∏è INVESTIGATION REQUIRED: Test Execution Performance

**Status**: üîç NEEDS INVESTIGATION BY CLAUDE CODE/GPT-5
**Discovered**: 2025-09-30 during codebase analysis
**Impact**: Tests appear to hang or run extremely slowly (2+ minutes, timing out)

### Observed Symptoms
- Test suite execution hangs/runs indefinitely when running `npm test`
- Tests may be timing out after 2 minutes
- Could indicate lingering timers, open handles, or infinite loops
- May validate the need for Phase 0 time source implementation

### Investigation Tasks
Before starting Phase 0, consider investigating:
1. **Check for lingering timers**: Run `npm test` and monitor for setTimeout/setInterval leaks
2. **Check for open database handles**: Look for unclosed SQLite connections
3. **Check for infinite loops**: Review test execution patterns for blocking operations
4. **Review recent changes**: Check if recent commits introduced timer/async issues

### Recommended Approach
**Option A**: Investigate first, then execute Phase 0-7
- Spend 30-60 minutes investigating root cause
- May identify quick fixes that accelerate overall execution
- Use `mcp__zen__debug` tool for systematic investigation

**Option B**: Proceed with Phase 0 immediately
- Phase 0 creates time source infrastructure that may resolve issues
- Can investigate if problems persist after Phase 0
- Faster path to visible progress

### Next Steps for Claude Code
When you encounter this note:
1. Acknowledge the test performance issue
2. Recommend investigation strategy to user
3. Get user approval on Option A (investigate) vs Option B (proceed with Phase 0)
4. Use debug tools if investigating (zen debug, test profiling, etc.)

**Note**: This investigation note will be removed once the issue is understood and documented.

---

## üìÅ Essential Documents (All in This Directory)

### Primary Execution Documents
1. **`docs/OPTION_A_COMPREHENSIVE_FIX_PLAN.md`** ‚≠ê **MAIN DOCUMENT**
   - Complete 8-phase execution plan
   - All 181 test failures analyzed and mapped
   - Code examples for every fix
   - Quality gates and verification steps
   - 50-60 hour timeline with phase breakdown

2. **`docs/GPT5_VALIDATION_SUMMARY.md`** üìä **VALIDATION RECORD**
   - Complete GPT-5 review and approval
   - Strategic insights and risk mitigation
   - Execution best practices
   - Why certain approaches were chosen

3. **`docs/GPT5_SURGICAL_ADJUSTMENTS_CHECKLIST.md`** ‚úÖ **ADJUSTMENTS TRACKER**
   - All 12 GPT-5 recommended adjustments
   - Status tracking (all now incorporated)
   - Code templates for each adjustment

### Supporting Documents
4. **`CLAUDE.md`** - Project context (this directory)
   - Current project status: v2.0 test remediation
   - Next task: Execute OPTION_A plan
   - Technology stack and architecture

5. **`.claude-context`** - Session state (this directory)
   - What was completed in previous session
   - Current test status: 816/1,002 passing (81.5%)
   - Zen MCP configuration status

### Reference Documents
6. **`docs/TEST_FAILURE_CLASSIFICATION.md`** (if exists)
   - Detailed failure categorization
   - Root cause analysis

7. **`docs/FINAL_TEST_STATUS.md`** (if exists)
   - Latest test run results
   - Failure patterns

---

## üéØ Execution Approach

### Mechanical Execution (Recommended)
The plan is **extremely detailed** - follow it mechanically:
- ‚úÖ Each phase has specific file paths
- ‚úÖ Every fix has code examples
- ‚úÖ All 181 tests are accounted for
- ‚úÖ Quality gates prevent rework
- ‚úÖ Commit messages templated

**Don't improvise** - the plan has been:
- Forensically analyzed by Error Investigator agent
- Validated by GPT-5 (two rounds)
- Refined with 12 surgical adjustments
- Sequenced for optimal dependency flow

### When to Deviate
Only deviate if:
- ‚ùå A fix in the plan doesn't work (document why, try alternative)
- ‚ùå Test has changed since plan creation
- ‚ùå Dependency issue prevents phase execution

Otherwise, **trust the plan**.

---

## üìä Progress Tracking

### After Each Phase
Update `.claude-context` with:
```markdown
## Phase X Complete (YYYY-MM-DD)
- Tests fixed: N
- New pass rate: XXX/1,002 (XX.X%)
- Time invested: X hours
- Issues encountered: [list any]
- Next phase: Phase Y
```

### Quality Gates (Run After Each Phase)
From `OPTION_A_COMPREHENSIVE_FIX_PLAN.md` Section "QUALITY GATES":

1. **Incremental Test Execution** - Run affected files first
2. **Policy Enforcement** - No new skipped tests, lint passes
3. **Performance Monitoring** - Track test duration
4. **Contract Validation** - Snapshot tests for adapters
5. **CI-Specific Checks** - Fake timers, cleanup verification
6. **Flake Detection** - Run phase tests 3x before proceeding
7. **Open Handle/Timer Guard** - Check for lingering timers (GPT-5 addition)
8. **API Client Contract** - Validate mock-real interface sync (GPT-5 addition)

**Critical**: Gates 7 & 8 are GPT-5 additions - don't skip them!

---

## üó∫Ô∏è Phase Overview

### Phase 0: Shared Utilities (1.5 hours, 0 tests) üèóÔ∏è
**Goal**: Build infrastructure used by all phases
**Files**: `src/utils/date-adapter.ts`, `src/utils/time-source.ts`, `tests/fixtures/index.ts`
**Why**: Prevents 3-4 hours of repeated work

### Phase 1: Memory & HTTPS Validation (3 hours, 8 tests) üß†
**Goal**: Fix memory tests, validation logic, configuration
**Risk**: Low

### Phase 2: Date & Database (6 hours, 17 tests) üìÖ
**Goal**: Standardize date handling, fix schema issues
**Risk**: Medium

### Phase 3A: Google Ads API - Foundation (6-8 hours, ~22 tests) üîå
**Goal**: GAQL builder, mocks, OAuth, query operations
**Risk**: Medium
**Note**: Phase 4 can start after 3A completes (don't wait for 3B)

### Phase 3B: Google Ads API - Mutations (6-8 hours, ~22 tests) üöÄ
**Goal**: Campaign/ad group/budget creation, error normalization
**Risk**: Medium-High

### Phase 4: Mutation Testing (4 hours, 10 tests) ‚úèÔ∏è
**Goal**: Rewrite mutation tests for current API
**Risk**: Medium
**Dependencies**: Phase 3A (can run parallel to 3B)

### Phase 5: Validation & Compliance (6 hours, 13 tests) üõ°Ô∏è
**Goal**: Complete validation and compliance systems
**Risk**: Medium

### Phase 6: Safe Write Operations (10 hours, 69 tests) üîí
**Goal**: Complete mutation safety system
**Risk**: High (safety-critical)
**GPT-5 Adjustments**: Retention lifecycle, CSV escaping, period fixes

### Phase 7: Integration & Polish (6 hours, 15 tests) üé®
**Goal**: Final integration tests and edge cases
**Risk**: Low
**GPT-5 Adjustment**: MCP compareCampaigns typo fix

---

## üö® Critical Success Factors

### 1. Follow Phase Order
Dependencies are carefully mapped:
- Phase 0 must complete before all others
- Phase 3A must complete before Phase 4
- Phase 6 requires Phases 1-5 complete

### 2. Use Quality Gates
**Every phase** must pass all 8 quality gates before proceeding.
This prevents rework and catches issues early.

### 3. Commit After Each Phase
Template from plan:
```bash
git commit -m "test: Phase N complete - +X tests passing

- [Summary of phase work]
- All quality gates passed
- Ready for Phase N+1

Pass rate: XXX/1,002 (XX.X%)"
```

### 4. Run Tests Incrementally
```bash
# Fast feedback - affected files only
npx vitest run [affected-file]

# Full validation
npx vitest run --retry=1

# Stability check (run 3x)
for i in {1..3}; do npx vitest run; done
```

### 5. Document Issues
If a fix doesn't work:
1. Document what happened
2. Try alternative from plan (if provided)
3. Consult GPT-5 via Zen MCP if stuck
4. Update `.claude-context` with findings

---

## üéì Understanding the Plan Structure

### Phase Sections
Each phase in `OPTION_A_COMPREHENSIVE_FIX_PLAN.md` has:

**Header**:
- Goal (what you're fixing)
- Risk level (low/medium/high)
- Dependencies (what must complete first)
- Time estimate

**Subsections** (e.g., 1.1, 1.2, 1.3):
- Specific file paths
- Root cause analysis
- Action (code examples)
- Tests fixed (by test number)

**Exit Criteria**:
- ‚úÖ Checklist of what must work
- Test count expectations
- New pass rate target

### Code Examples
All code examples in the plan are **production-ready**:
- ‚úÖ Use exact file paths
- ‚úÖ Include all necessary imports
- ‚úÖ Show full method implementations
- ‚úÖ Include GPT-5 adjustments where applicable

**Just copy and adapt** - don't reinvent.

---

## üìû Getting Help

### If Stuck on a Phase
1. **Re-read the phase section** in `OPTION_A_COMPREHENSIVE_FIX_PLAN.md`
2. **Check GPT-5 validation** in `GPT5_VALIDATION_SUMMARY.md` for context
3. **Consult Zen MCP** (instB, port 7512) - GPT-5 available for discussion
4. **Review quality gates** - might reveal what's wrong

### If Tests Still Failing
1. **Run single test** with verbose output: `npx vitest run [file] --reporter=verbose`
2. **Check for new failures** - might be regression from earlier phase
3. **Verify dependencies** - earlier phase might not be complete
4. **Review test itself** - might need adjustment beyond plan

### If Timeline Slipping
- **Focus on quality gates** - they prevent rework
- **Don't batch phases** - commit after each one
- **Use Zen MCP GPT-5** - can help unstick issues faster

---

## ‚úÖ Final Success Criteria

Before marking complete:

### Quantitative
- ‚úÖ 1,002/1,002 tests passing (100%)
- ‚úÖ v2.0 Core: 66/66 tests maintained (100%)
- ‚úÖ Zero TypeScript compilation errors
- ‚úÖ Test suite completes in < 15 seconds
- ‚úÖ 3x stability check passes (same results every run)

### Qualitative
- ‚úÖ All phases committed with clear messages
- ‚úÖ `.claude-context` updated with completion status
- ‚úÖ No skipped tests (or documented with TODO + owner)
- ‚úÖ All quality gates validated
- ‚úÖ Documentation updated

---

## üé¨ Ready to Start?

**Your first command**:
```bash
# Verify current test status
npx vitest run

# Expected: 816/1,002 passing (81.5%)
# Target: 1,002/1,002 passing (100%)
```

**Your first task**:
1. Open `docs/OPTION_A_COMPREHENSIVE_FIX_PLAN.md`
2. Read Phase 0 section (lines 80-270)
3. Create `src/utils/date-adapter.ts` as specified
4. Start mechanical execution

**Remember**: Trust the plan. It's been thoroughly validated and is ready to execute.

---

**Good luck! You've got this.** üöÄ

The plan is comprehensive, validated by GPT-5, and accounts for all 181 failures. Follow it mechanically, use the quality gates, and commit frequently.

**Estimated completion**: 7-10 working days
**Current pass rate**: 816/1,002 (81.5%)
**Target pass rate**: 1,002/1,002 (100%)